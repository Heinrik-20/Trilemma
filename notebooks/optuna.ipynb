{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/quant/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Workflow\n",
    "## We can first run to get the important parameters first, and then look to optimise only those specific ones\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/../src/\")\n",
    "\n",
    "from utils import create_dataset\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import SplineTransformer, PowerTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "btc = create_dataset()\n",
    "btc = btc.reset_index(drop=True)\n",
    "\n",
    "X_pred = btc.iloc[-1].drop(['Date', 'target'])\n",
    "btc = btc.dropna()\n",
    "\n",
    "X, y = btc.drop(columns=['target', 'Date']).astype(np.float64), btc['target'].astype(np.float64)\n",
    "\n",
    "SEED = 2052\n",
    "np.random.seed(SEED)\n",
    "TS_SPLITS = 10\n",
    "NCALLS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    def suggest_params(trial):\n",
    "\n",
    "        return {\n",
    "            'spline': {\n",
    "                'n_knots': trial.suggest_int('n_knots', 5, 20),\n",
    "                'degree': trial.suggest_int('degree', 2, 5)\n",
    "            },\n",
    "\n",
    "            'svm': {\n",
    "                'kernel': trial.suggest_categorical('svm__kernel', ['rbf', 'sigmoid']),\n",
    "                'gamma': trial.suggest_float('svm__gamma', 1e-5, 1),\n",
    "                'C': trial.suggest_float('svm__C', 1, 1e2),\n",
    "                'epsilon': trial.suggest_float('svm__epsilon', 1e-1, 1e1),\n",
    "                'max_iter': 20000,\n",
    "            },\n",
    "\n",
    "            'rf': {\n",
    "                'n_estimators': trial.suggest_int('rf__n_estimators', 100, 450),\n",
    "                'max_depth': trial.suggest_int('rf__max_depth', 4, 50),\n",
    "                'min_samples_split': trial.suggest_int('rf__min_samples_split', 2, 15),\n",
    "                'min_samples_leaf': trial.suggest_int('rf__min_samples_leaf', 2, 15),\n",
    "                'max_features': trial.suggest_categorical('rf__max_features', ['sqrt', 'log2', 1.0]),\n",
    "                'min_impurity_decrease': trial.suggest_float('rf__min_impurity_decrease', 0, 1),\n",
    "                'ccp_alpha': trial.suggest_float('rf__ccp_alpha', 0, 10),\n",
    "                'random_state': SEED\n",
    "            },\n",
    "\n",
    "            'ada': {\n",
    "                'n_estimators': trial.suggest_int('ada__n_estimators', 50, 350),\n",
    "                'learning_rate': trial.suggest_float('ada__learning_rate', 1e-5, 1e3),\n",
    "                'loss': trial.suggest_categorical('ada__loss', ['linear', 'square', 'exponential']),\n",
    "                'random_state': SEED\n",
    "\n",
    "            },\n",
    "\n",
    "            'lgbm': {\n",
    "                'n_estimators': trial.suggest_int('lgbm__n_estimators', 500, 3000),\n",
    "                'max_depth': trial.suggest_int('lgbm__max_depth', 4, 50),\n",
    "                'min_child_weight': trial.suggest_int('lgbm__min_child_weight', 1, 6),\n",
    "                'learning_rate': trial.suggest_float('lgbm__learning_rate', 1e-5, 1),\n",
    "                'reg_alpha': trial.suggest_float('lgbm__reg_alpha', 0, 1e1),\n",
    "                'reg_lambda': trial.suggest_float('lgbm__reg_lambda', 0, 1e1),\n",
    "                'verbosity': -1,\n",
    "                'random_state': SEED\n",
    "            },\n",
    "        }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    ts_cv = TimeSeriesSplit(\n",
    "        n_splits=TS_SPLITS,\n",
    "        test_size=1\n",
    "    )\n",
    "\n",
    "\n",
    "    for index, (train_index, test_index) in enumerate(ts_cv.split(X)):\n",
    "\n",
    "        ## Time series split\n",
    "        X_train = X.values[train_index]\n",
    "        y_train = y.values[train_index]\n",
    "\n",
    "        X_val = X.values[test_index].reshape(1, -1)\n",
    "        y_val = y.values[test_index]\n",
    "\n",
    "        ## Suggesting parameters\n",
    "        params = suggest_params(trial=trial)\n",
    "        spline, svm, rf, ada, lgbm = params['spline'], params['svm'], params['rf'], params['ada'], params['lgbm']\n",
    "\n",
    "        ## Construction of model\n",
    "        ensemble = VotingRegressor(\n",
    "            estimators=[\n",
    "                ('svm', SVR(**svm)),\n",
    "                ('rf', RandomForestRegressor(**rf)),\n",
    "                ('ada', AdaBoostRegressor(**ada)),\n",
    "                ('lgbm', LGBMRegressor(**lgbm))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('power-transformer', PowerTransformer()),\n",
    "                ('spline', SplineTransformer(**spline)),\n",
    "                ('ensemble', ensemble)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        pipeline.fit(X=X_train, y=y_train)\n",
    "        y_pred = pipeline.predict(X=X_val)\n",
    "\n",
    "        # Scoring\n",
    "        score = np.abs(y_val - y_pred)\n",
    "        scores.append(score)\n",
    "        trial.report(np.mean(scores), index)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"./logs/\"\n",
    "file = \"optuna_run\"\n",
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(log_path, file))\n",
    "optuna_logger = optuna.logging.get_logger(\"optuna\")\n",
    "optuna_logger.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:32:00,795] A new study created in memory with name: Ensemble Optimisation\n",
      "[I 2024-07-14 16:32:21,916] Trial 0 finished with value: 10.960065623445725 and parameters: {'n_knots': 8, 'degree': 2, 'svm__kernel': 'rbf', 'svm__gamma': 0.695729436385686, 'svm__C': 2699.5483818842795, 'svm__epsilon': 2518.8933302217097, 'rf__n_estimators': 317, 'rf__max_depth': 4, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 9, 'rf__max_features': 1.0, 'rf__min_impurity_decrease': 0.7760441500816841, 'rf__ccp_alpha': 99.6328493202434, 'ada__n_estimators': 164, 'ada__learning_rate': 658.8545009428428, 'ada__loss': 'square', 'lgbm__n_estimators': 2113, 'lgbm__max_depth': 12, 'lgbm__min_child_weight': 6, 'lgbm__learning_rate': 0.8569605441961466, 'lgbm__reg_alpha': 39.45791987972184, 'lgbm__reg_lambda': 8.61273070874762}. Best is trial 0 with value: 10.960065623445725.\n",
      "[I 2024-07-14 16:32:44,861] Trial 1 finished with value: 7.8705515491141735 and parameters: {'n_knots': 5, 'degree': 5, 'svm__kernel': 'rbf', 'svm__gamma': 0.3314045453422991, 'svm__C': 4863.556071422096, 'svm__epsilon': 7139.446289128527, 'rf__n_estimators': 212, 'rf__max_depth': 4, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 5, 'rf__max_features': 1.0, 'rf__min_impurity_decrease': 0.822172721127257, 'rf__ccp_alpha': 16.331359784192482, 'ada__n_estimators': 283, 'ada__learning_rate': 885.9105602839786, 'ada__loss': 'exponential', 'lgbm__n_estimators': 1509, 'lgbm__max_depth': 4, 'lgbm__min_child_weight': 2, 'lgbm__learning_rate': 0.3814426514578559, 'lgbm__reg_alpha': 92.51997252399163, 'lgbm__reg_lambda': 72.48621348614887}. Best is trial 1 with value: 7.8705515491141735.\n",
      "[I 2024-07-14 16:33:18,766] Trial 2 finished with value: 11.134210545242139 and parameters: {'n_knots': 13, 'degree': 4, 'svm__kernel': 'sigmoid', 'svm__gamma': 0.4444024149875832, 'svm__C': 8399.832990701958, 'svm__epsilon': 9377.534015007286, 'rf__n_estimators': 288, 'rf__max_depth': 16, 'rf__min_samples_split': 4, 'rf__min_samples_leaf': 2, 'rf__max_features': 1.0, 'rf__min_impurity_decrease': 0.6919867109658043, 'rf__ccp_alpha': 70.4420060041789, 'ada__n_estimators': 320, 'ada__learning_rate': 278.90450553583264, 'ada__loss': 'exponential', 'lgbm__n_estimators': 2196, 'lgbm__max_depth': 9, 'lgbm__min_child_weight': 4, 'lgbm__learning_rate': 0.981406302410939, 'lgbm__reg_alpha': 84.2555281021142, 'lgbm__reg_lambda': 12.247175760011121}. Best is trial 1 with value: 7.8705515491141735.\n",
      "[I 2024-07-14 16:33:49,089] Trial 3 finished with value: 8.16206379992007 and parameters: {'n_knots': 11, 'degree': 2, 'svm__kernel': 'sigmoid', 'svm__gamma': 0.44721962434567797, 'svm__C': 5741.578237255258, 'svm__epsilon': 7001.919994053442, 'rf__n_estimators': 405, 'rf__max_depth': 14, 'rf__min_samples_split': 3, 'rf__min_samples_leaf': 6, 'rf__max_features': 1.0, 'rf__min_impurity_decrease': 0.523880886965937, 'rf__ccp_alpha': 10.684482792989881, 'ada__n_estimators': 131, 'ada__learning_rate': 341.01102878311866, 'ada__loss': 'square', 'lgbm__n_estimators': 1484, 'lgbm__max_depth': 12, 'lgbm__min_child_weight': 5, 'lgbm__learning_rate': 0.8303751815775484, 'lgbm__reg_alpha': 79.39310425570923, 'lgbm__reg_lambda': 66.95508279909018}. Best is trial 1 with value: 7.8705515491141735.\n",
      "[I 2024-07-14 16:33:58,363] Trial 4 finished with value: 7.918984732666402 and parameters: {'n_knots': 8, 'degree': 4, 'svm__kernel': 'rbf', 'svm__gamma': 0.3907585807972869, 'svm__C': 9266.020330758633, 'svm__epsilon': 747.0051826995215, 'rf__n_estimators': 323, 'rf__max_depth': 12, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__min_impurity_decrease': 0.9898913812386245, 'rf__ccp_alpha': 0.1594318424719246, 'ada__n_estimators': 273, 'ada__learning_rate': 652.6523023481028, 'ada__loss': 'linear', 'lgbm__n_estimators': 914, 'lgbm__max_depth': 8, 'lgbm__min_child_weight': 2, 'lgbm__learning_rate': 0.35091303225875053, 'lgbm__reg_alpha': 34.89341518908287, 'lgbm__reg_lambda': 39.73192947490604}. Best is trial 1 with value: 7.8705515491141735.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name='Ensemble Optimisation', pruner=optuna.pruners.MedianPruner(), direction='minimize')\n",
    "study.optimize(objective, n_trials=NCALLS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
