{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Workflow\n",
    "## We can first run to get the important parameters first, and then look to optimise only those specific ones\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/../src/\")\n",
    "\n",
    "from utils import create_dataset\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import SplineTransformer, PowerTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "btc = create_dataset()\n",
    "btc = btc.reset_index(drop=True)\n",
    "\n",
    "X_pred = btc.iloc[-1].drop(['Date', 'target'])\n",
    "btc = btc.dropna()\n",
    "\n",
    "X, y = btc.drop(columns=['target', 'Date']).astype(np.float64), btc['target'].astype(np.float64)\n",
    "\n",
    "SEED = 2052\n",
    "np.random.seed(SEED)\n",
    "TS_SPLITS = 10\n",
    "NCALLS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    def suggest_params(trial):\n",
    "\n",
    "        return {\n",
    "            'spline': {\n",
    "                'n_knots': trial.suggest_int('n_knots', 5, 20),\n",
    "                'degree': trial.suggest_int('degree', 2, 5)\n",
    "            },\n",
    "\n",
    "            'svm': {\n",
    "                'kernel': trial.suggest_categorical('svm__kernel', ['rbf', 'sigmoid']),\n",
    "                'gamma': trial.suggest_float('svm__gamma', 1e-5, 1),\n",
    "                'C': trial.suggest_float('svm__C', 1, 1e2),\n",
    "                'epsilon': trial.suggest_float('svm__epsilon', 1e-1, 1e1),\n",
    "                'max_iter': 20000,\n",
    "            },\n",
    "\n",
    "            'rf': {\n",
    "                'n_estimators': trial.suggest_int('rf__n_estimators', 100, 450),\n",
    "                'max_depth': trial.suggest_int('rf__max_depth', 4, 50),\n",
    "                'min_samples_split': trial.suggest_int('rf__min_samples_split', 2, 15),\n",
    "                'min_samples_leaf': trial.suggest_int('rf__min_samples_leaf', 2, 15),\n",
    "                'max_features': trial.suggest_categorical('rf__max_features', ['sqrt', 'log2', 1.0]),\n",
    "                'min_impurity_decrease': trial.suggest_float('rf__min_impurity_decrease', 0, 1),\n",
    "                'ccp_alpha': trial.suggest_float('rf__ccp_alpha', 0, 10),\n",
    "                'random_state': SEED\n",
    "            },\n",
    "\n",
    "            'ada': {\n",
    "                'n_estimators': trial.suggest_int('ada__n_estimators', 50, 350),\n",
    "                'learning_rate': trial.suggest_float('ada__learning_rate', 1e-5, 1e3),\n",
    "                'loss': trial.suggest_categorical('ada__loss', ['linear', 'square', 'exponential']),\n",
    "                'random_state': SEED\n",
    "\n",
    "            },\n",
    "\n",
    "            'lgbm': {\n",
    "                'n_estimators': trial.suggest_int('lgbm__n_estimators', 500, 3000),\n",
    "                'max_depth': trial.suggest_int('lgbm__max_depth', 4, 50),\n",
    "                'min_child_weight': trial.suggest_int('lgbm__min_child_weight', 1, 6),\n",
    "                'learning_rate': trial.suggest_float('lgbm__learning_rate', 1e-5, 1),\n",
    "                'reg_alpha': trial.suggest_float('lgbm__reg_alpha', 0, 1e1),\n",
    "                'reg_lambda': trial.suggest_float('lgbm__reg_lambda', 0, 1e1),\n",
    "                'verbosity': -1,\n",
    "                'random_state': SEED\n",
    "            },\n",
    "\n",
    "            'ridge': {\n",
    "                'alpha': trial.suggest_float('lgbm__learning_rate', 1, 10),\n",
    "                'random_state': SEED,\n",
    "            },\n",
    "\n",
    "        }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    ts_cv = TimeSeriesSplit(\n",
    "        n_splits=TS_SPLITS,\n",
    "        test_size=1\n",
    "    )\n",
    "\n",
    "\n",
    "    for index, (train_index, test_index) in enumerate(ts_cv.split(X)):\n",
    "\n",
    "        ## Time series split\n",
    "        X_train = X.values[train_index]\n",
    "        y_train = y.values[train_index]\n",
    "\n",
    "        X_val = X.values[test_index].reshape(1, -1)\n",
    "        y_val = y.values[test_index]\n",
    "\n",
    "        ## Suggesting parameters\n",
    "        params = suggest_params(trial=trial)\n",
    "        spline, svm, rf, ada, lgbm, ridge = params['spline'], params['svm'], params['rf'], params['ada'], params['lgbm'], params['ridge']\n",
    "        ada['estimator'] = LGBMRegressor(**lgbm)\n",
    "\n",
    "        ## Construction of model\n",
    "        ensemble = StackingRegressor(\n",
    "            estimators=[\n",
    "                ('svm', SVR(**svm)),\n",
    "                ('rf', RandomForestRegressor(**rf)),\n",
    "                ('ridge', Ridge(**ridge))\n",
    "            ],\n",
    "            final_estimator=AdaBoostRegressor(**ada)\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('power-transformer', PowerTransformer()),\n",
    "                ('spline', SplineTransformer(**spline)),\n",
    "                ('ensemble', ensemble)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        pipeline.fit(X=X_train, y=y_train)\n",
    "        y_pred = pipeline.predict(X=X_val)\n",
    "\n",
    "        # Scoring\n",
    "        score = np.abs(y_val - y_pred)\n",
    "        scores.append(score)\n",
    "        trial.report(np.mean(scores), index)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"./logs/\"\n",
    "file = \"optuna_run\"\n",
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(log_path, file))\n",
    "optuna_logger = optuna.logging.get_logger(\"optuna\")\n",
    "optuna_logger.addHandler(fileHandler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
